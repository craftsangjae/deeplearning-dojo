{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The understanding of Shake-Shake Regularization and the implementation of Layer using `tf.keras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연구의 모티브\n",
    "\n",
    "딥러닝의 Overfitting 문제를 해결하는 수단을 찾아보자! <br>\n",
    "$\\rightarrow$ 가장 쉬운 방식은 Data Augmentation, 데이터에 노이즈를 잔뜩 주자 <br>\n",
    "$\\rightarrow$ 그래봤자 Data Augmentation은 모델 내부의 표현(Intermediate representation)에는 큰 변화를 주지 못한다.<br> \n",
    "$\\rightarrow$ 어떻게 모델 내부 표현에 노이즈를 줄까?<br>\n",
    "$\\rightarrow$ 요즘 유행하는 **Multi-Branch**의 구조를 한번 이용해볼까!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최근 Mutli-Branch의 대표적인 모델인 Res-Next를 살펴보자!\n",
    "\n",
    "<Resnet과 ResNext의 차이에 대한 그림>\n",
    "\n",
    "![](https://miro.medium.com/max/1468/1*LOoc11tkDoqv0pC6OH7mwA.png)\n",
    "\n",
    "\n",
    "같은 Residual Block 내에서 ResNext는 그룹 단위로 쪼개고(split), 각 그룹 별로 변환하고 (Affine Transform), 각 그룹의 결과를 모아줌으로써 처리한다. <br>\n",
    "그렇게 하면, 연산량이나 파라미터가 크게 오르지 않을까? $\\rightarrow$ 그렇지 않다!\n",
    "\n",
    "![Imgur](https://i.imgur.com/RgV2KZS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 BottleNeck으로 줄였다가(Squeeze), Group Convolution을 적용한 거랑 동일한 구조이다. 그래서 파라미터의 크기는 아래와 같다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet에서의 Param 수 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69632"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 * 1 * 1* 64 + 64 * 3 * 3 * 64 + 64 * 1 * 1* 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Res-Next에서의 param 수 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32* (256 * 1 * 1* 4 + 4 * 3 * 3 * 4 + 4 * 1* 1* 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 레이어를 구성하면, 파라미터 수도 거의 비슷하고, 연산량도 거의 비슷하게 유지된다!. 그런데 성능은 크게 향상된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/Fyh8EYm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보면 복잡도를 2배씩 올린 모델의 성능 향상보다, Cardiality, 즉 Group으로 나누어 처리하게한 ResNext가 성능향상이 더 되었다!\n",
    "\n",
    "연구의 모티브는 바로 이 Multi-Branch 아이디어를 활용하여, **\"Regularization 효과까지 한번 만들어보겠다\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 연구\n",
    "\n",
    "#### (1) Fractal-Net\n",
    "\n",
    "이런 아이디어로 처음 나온 것은 Residual Network 없이 충분히 깊게 쌓아보자 라는 아이디어로 만들어진 Fractal-Net이 있다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/pZbx4Sj.png)\n",
    "\n",
    "이런 식으로 매 학습때마다 Feed Forward하는 경로를 랜덤하게 결정!(50%확률로 Local 방식으로 path Sampling하고 50% 확률로 Global 방식으로 Path Sampling)\n",
    "\n",
    "이 사람은 Multi-Branch의 경로를 랜덤하게 해줌으로써 모델에 Regularization 효과를 제공하는 방식 (어떻게 보면, Dropout의 일종, 뉴런을 켰다 껐다 하는 대신 작은 네트워크를 켰다 껐다 하는 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Shakeout \n",
    "\n",
    "껐다 켰다 하는 Dropout 대신, 뉴런의 출력을 변경하는 네트워크 (Paper를 구체적으로 살펴보지 못해서 이해하지 못했습니다)\n",
    "\n",
    "![Imgur](https://i.imgur.com/sRED6I9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shake-Shake Network이 어떤 식으로 동작하는지를 설명하는 그림입니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/3onSLc5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 연산을 이해하기 위해서 먼저 뿌리가 되는 Res-Net부터 살펴보도록 하겠습니다. Residual Network라면 아래와 같이 구성됩니다.\n",
    "![Imgur](https://i.imgur.com/FpBLEvg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 Res Net은 수식으로 보면 아래와 같은 수식입니다.\n",
    "\n",
    "$$\n",
    "x_{i+1} = x_i + \\mathcal{F}(x_i,\\mathcal{W}_i) \n",
    "$$\n",
    "\n",
    "Shake Shake Regularization에서는 두 개의 Residual Block을 병렬로 두게 됩니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/tNwYQWK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 위의 연산을 수식으로 나타내면 아래와 같습니다. \n",
    "\n",
    "$$\n",
    "x_{i+1} = x_i + \\alpha_i \\mathcal{F}(x_i,\\mathcal{W}_i^{(1)})  + (1- \\alpha_i) \\mathcal{F}(x_i,\\mathcal{W}_i^{(2)})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때의 $\\alpha$는 random value로, 0과 1사이의 균등분포에서 무작위로 추출한 값이 됩니다. 즉 왼쪽과 오른쪽의 브랜치에 대한 피처맵 가중치는 매번 바뀌는 값이 됩니다. \n",
    "\n",
    "Shake-Shake 네트워크에서 독특한 점은 바로 아래, BackPropagation할 때에 있습니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/XDfbzJf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed Forward 때와 달리, Backward에서 랜덤 값을 다른 것으로 줍니다. <br>\n",
    "즉 Gradient의 움직임에 노이즈를 주는 아이디어 입니다. 저자들은 이 아이디어에 대해 아래와 같이 설명합니다. \n",
    "\n",
    "\n",
    "> As shown in Figure 1, all scaling coefficients are overwritten with new random numbers before each\n",
    "forward pass. **The key to making this work is to repeat this coefficient update operation before each\n",
    "backward pass.** This results in a stochastic blend of forward and backward flows during training.\n",
    "Related to this idea are the works of An (1996) and Neelakantan et al. (2015). These authors showed\n",
    "that adding noise to the gradient during training helps training and generalization of complicated\n",
    "neural networks. Shake-Shake regularization can be seen as an extension of this concept where\n",
    "gradient noise is replaced by a form of gradient augmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방식으로 모델을 학습시켰을 때, CIFAR-10에서의 Error rate는 아래와 같습니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/xRnoX5g.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[paper with code - Leader Board of CIFAR-10](https://paperswithcode.com/sota/image-classification-on-cifar-10)에서 살펴보았을 때에도, ShakeShake 아이디어를 접목한 모델들이 상위권에 기재되어 있습니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/gZFflr4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras로 간결하게, 그리고 매우 잘 구현된 코드가 있습니다.<br>\n",
    "*(caution : 가독성을 위해, 약간의 refactoring을 거쳤습니다.)* <br>\n",
    "[keras-shake-shake layers](https://github.com/jonnedtc/Shake-Shake-Keras/blob/master/layers.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class ShakeShake(Layer):\n",
    "    \"\"\" Shake-Shake-Image Layer \"\"\"\n",
    "    def __init__(self, verbose=False, **kwargs):\n",
    "        self.verbose = verbose\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        left, right = inputs # unpack left and right\n",
    "        \n",
    "        batch_size = K.shape(left)[0]\n",
    "        alpha = K.random_uniform((batch_size, 1, 1, 1))\n",
    "        beta = K.random_uniform((batch_size, 1, 1, 1))\n",
    "\n",
    "        # Shake-Shake-Image\n",
    "        def shake():\n",
    "            forward = alpha * left + (1 - alpha) * right \n",
    "            backward = beta * left + (1 - beta) * right\n",
    "            return backward + K.stop_gradient(forward - backward)\n",
    "        \n",
    "        # even during testing phase\n",
    "        def even():\n",
    "            return 0.5 * left + 0.5 * right\n",
    "        \n",
    "        if self.verbose:\n",
    "            # Check 되면, alpha & beta값 보임\n",
    "            op1 = K.print_tensor(alpha, \"alpha : \")\n",
    "            op2 = K.print_tensor(beta, \"beta : \")        \n",
    "            with tf.control_dependencies([op1]):\n",
    "                with tf.control_dependencies([op2]):\n",
    "                    return K.in_train_phase(shake, even)\n",
    "        else:\n",
    "            return K.in_train_phase(shake, even)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shake-Shake은 두가지 Input을 받습니다. left와 right는 각각의 branch를 지칭합니다. 위 모델이 잘 돌아가는지를 파악하기 위해서 아래와 같은 테스트 코드를 작성해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = Input((1,))\n",
    "\n",
    "left_branch_layer = Dense(1, use_bias=False)\n",
    "right_branch_layer = Dense(1, use_bias=False)\n",
    "\n",
    "left  = left_branch_layer(inputs)\n",
    "right = right_branch_layer(inputs)\n",
    "outputs = ShakeShake(verbose=True)([left, right])\n",
    "\n",
    "model = Model(inputs, outputs, name='shake-shake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 동작을 보다 간단하게 확인하기 위해, 왼쪽 브랜치의 가중치를 1, 오른쪽 브랜치의 가중치를 -1로 두겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_branch_layer.set_weights(np.array([[[1]]]))\n",
    "right_branch_layer.set_weights(np.array([[[-1]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습환경에서의 FeedForward는 alpha값에 따라 아래와 같이 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  [[[[0.570445538]]]]\n",
      "beta :  [[[[0.723735452]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.14089108]]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.get_session().run(outputs, feed_dict={inputs:np.array([[1]]),\n",
    "                                       K.learning_phase(): True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론 환경(Test 환경)에서는 EVEN, 왼쪽과 오른쪽 모두 동일한 가중치를 주게 되므로, 0이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  [[[[0.208138108]]]]\n",
      "beta :  [[[[0.836968064]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.get_session().run(outputs, feed_dict={inputs:np.array([[1]]),\n",
    "                                       K.learning_phase(): False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습환경에서의 Backward는 Backward값에 따라 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  [[[[0.869900942]]]]\n",
      "beta :  [[[[0.399321795]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.20135641]], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = tf.gradients(outputs, inputs)\n",
    "\n",
    "K.get_session().run(grad, feed_dict={inputs:np.array([[1]]),\n",
    "                                     K.learning_phase(): True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 움직임을 통해 `ShakeShake`코드가 정상적으로 돌아가는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional (1)] ShakeEven은 아래와 같이 작성하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakeEven(Layer):\n",
    "    \"\"\" Shake-Even-Image Layer \"\"\"\n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        left, right = inputs # unpack x1 and x2\n",
    "        \n",
    "        batch_size = K.shape(left)[0]\n",
    "        alpha = K.random_uniform((batch_size, 1, 1, 1))\n",
    "\n",
    "        # Shake-Even-Image\n",
    "        def shake_shake():\n",
    "            forward = alpha * left + (1 - alpha) * right \n",
    "            backward = 0.5 * left + 0.5 * right\n",
    "            return backward + K.stop_gradient(forward - backward)\n",
    "        \n",
    "        # even during testing phase\n",
    "        def even():\n",
    "            return 0.5 * left + 0.5 * right\n",
    "        \n",
    "        return K.in_train_phase(shake, even)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional (2)] 텐서플로우에서는 아래와 같은 방식으로 Override해서 구현해야 합니다. <br>\n",
    "\n",
    "reference : [Tensorflow: How to replace or modify gradient](https://stackoverflow.com/questions/43839431/tensorflow-how-to-replace-or-modify-gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/smT72Jb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 사용 예시는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate, Input\n",
    "from tensorflow.keras.models import load_model, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_residual_branch(x, filters, stride):\n",
    "    \"\"\" Regular Branch of a Residual network: ReLU -> Conv2D -> BN repeated twice \"\"\"\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, 3, strides=stride, padding='same',\n",
    "               kernel_initializer='he_normal', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='same',\n",
    "               kernel_initializer='he_normal', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_residual_shortcut(x, filters, stride):\n",
    "    \"\"\" Shortcut Branch used when downsampling from Shake-Shake regularization \"\"\"\n",
    "    x = ReLU()(x)\n",
    "    x1 = x[:,0:-1:stride, 0:-1:stride]\n",
    "    x1 = Conv2D(filters // 2, 1, strides=1, padding='valid',\n",
    "                kernel_initializer='he_normal', use_bias=False)(x1)\n",
    "    x2 = x[:,1::stride, 1::stride]\n",
    "    x2 = Conv2D(filters // 2, 1, strides=1, padding='valid',\n",
    "                kernel_initializer='he_normal', use_bias=False)(x2)\n",
    "    x = Concatenate()([x1, x2])\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_residual_block(x, filters, stride=1):\n",
    "    \"\"\" Residual Block with Shake-Shake regularization and shortcut \"\"\"\n",
    "    x1 = create_residual_branch(x, filters, stride)\n",
    "    x2 = create_residual_branch(x, filters, stride)\n",
    "    if stride > 1: \n",
    "        x = create_residual_shortcut(x, filters, stride)\n",
    "    return x + ShakeShake()([x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "* **논문** : \n",
    "    1. [Shake-Shake Regularization](https://arxiv.org/pdf/1705.07485.pdf)\n",
    "    2. [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/pdf/1611.05431.pdf)\n",
    "    3. [FractalNet: ULTRA-DEEP NEURAL NETWORKS WITHOUT RESIDUALS](https://arxiv.org/pdf/1605.07648.pdf)\n",
    "    4. [Shakeout: A New Regularized Deep\n",
    "Neural Network Training Scheme](https://pdfs.semanticscholar.org/310e/c7796eeca484d734399d9979e8f74d7d8ed2.pdf)\n",
    "\n",
    "* **블로그** : \n",
    "    1. [SUALAB Blog - Shake-Shake Regularization](http://research.sualab.com/practice/review/2018/06/28/shake-shake-regularization-review.html)\n",
    "    2. [CIFAR-10 정복하기 3: Shake-Shake](https://dnddnjs.github.io/cifar10/2018/10/25/shake_shake/)\n",
    "    3. [Shake-Shake Regularization with Interactive Code](https://medium.com/@SeoJaeDuk/shake-shake-regularization-with-interactive-code-manual-back-prop-with-tf-20505cb21a9e)\n",
    "\n",
    "* **깃헙** : \n",
    "    1. [shake-shake-keras/](https://github.com/jonnedtc/Shake-Shake-Keras/blob/master/layers.py)\n",
    "\n",
    "* **스택오버플로우** : \n",
    "    1. : [tensorflow-how-to-replace-or-modify-gradient](https://stackoverflow.com/questions/43839431/tensorflow-how-to-replace-or-modify-gradient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
